{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames per second :  0.0 FPS\n",
      "Frame count :  -1.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "# Create a video capture object, in this case we are reading the video from a file\n",
    "\n",
    "vid_capture = cv2.VideoCapture(0,cv2.CAP_DSHOW)\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades +'haarcascade_frontalface_default.xml')\n",
    "if (vid_capture.isOpened() == False):  \n",
    "  print(\"Error opening the video file\")\n",
    "  # Read fps and frame count\n",
    "else:\n",
    "    # Get frame rate information\n",
    "    # You can replace 5 with CAP_PROP_FPS as well, they are enumerations\n",
    "    fps = vid_capture.get(5)\n",
    "    print('Frames per second : ', fps,'FPS')\n",
    "    # Get frame count\n",
    "    # You can replace 7 with CAP_PROP_FRAME_COUNT as well, they are enumerations\n",
    "    frame_count = vid_capture.get(7)\n",
    "    print('Frame count : ', frame_count)\n",
    " \n",
    "while(vid_capture.isOpened()):\n",
    "  # vid_capture.read() methods returns a tuple, first element is a bool\n",
    "  # and the second is frame\n",
    "  ret, frame = vid_capture.read()\n",
    "  warna = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "   \n",
    "  face = face_cascade.detectMultiScale(warna,2,5)\n",
    "  if ret == True:\n",
    "    for (x,y,w,h) in face :\n",
    "        frame = cv2.rectangle(frame, (x,y), (x+w, y+h), (0, 255, 63), 6)\n",
    "        muka = warna[y : y+h, x: x+w]\n",
    "    cv2.imshow('Frame',frame)\n",
    "    # 20 is in milliseconds, try to increase the value, say 50 and observe\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "      break\n",
    "  else:\n",
    "    break\n",
    " \n",
    "# Release the video capture object\n",
    "vid_capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function detectMultiScale:\n",
      "\n",
      "detectMultiScale(...) method of cv2.CascadeClassifier instance\n",
      "    detectMultiScale(image[, scaleFactor[, minNeighbors[, flags[, minSize[, maxSize]]]]]) -> objects\n",
      "    .   @brief Detects objects of different sizes in the input image. The detected objects are returned as a list\n",
      "    .       of rectangles.\n",
      "    .   \n",
      "    .       @param image Matrix of the type CV_8U containing an image where objects are detected.\n",
      "    .       @param objects Vector of rectangles where each rectangle contains the detected object, the\n",
      "    .       rectangles may be partially outside the original image.\n",
      "    .       @param scaleFactor Parameter specifying how much the image size is reduced at each image scale.\n",
      "    .       @param minNeighbors Parameter specifying how many neighbors each candidate rectangle should have\n",
      "    .       to retain it.\n",
      "    .       @param flags Parameter with the same meaning for an old cascade as in the function\n",
      "    .       cvHaarDetectObjects. It is not used for a new cascade.\n",
      "    .       @param minSize Minimum possible object size. Objects smaller than that are ignored.\n",
      "    .       @param maxSize Maximum possible object size. Objects larger than that are ignored. If `maxSize == minSize` model is evaluated on single scale.\n",
      "    .   \n",
      "    .       The function is parallelized with the TBB library.\n",
      "    .   \n",
      "    .       @note\n",
      "    .          -   (Python) A face detection example using cascade classifiers can be found at\n",
      "    .               opencv_source_code/samples/python/facedetect.py\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(face_cascade.detectMultiScale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
